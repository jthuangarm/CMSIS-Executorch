/*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 * All rights reserved.
 *
 * This source code is licensed under the BSD-style license found in the
 * LICENSE file in the root directory of this source tree.
 */

// clang-format off
#pragma once

#include <tuple>

#include <ATen/ATen.h>
#include <torch/torch.h>

// @generated by gen.py from NativeFunctions.h

namespace cortex_m {
namespace native {
TORCH_API at::Tensor & quantize_per_tensor_out(const at::Tensor & input, double scale, int64_t zero_point, int64_t quant_min, int64_t quant_max, at::ScalarType dtype, at::Tensor & out);
TORCH_API at::Tensor & dequantize_per_tensor_out(const at::Tensor & input, double scale, int64_t zero_point, int64_t quant_min, int64_t quant_max, at::ScalarType dtype, at::Tensor & out);
TORCH_API at::Tensor quantized_add(const at::Tensor & self, const at::Scalar & self_zero_point, const at::Scalar & self_multiplier, const at::Scalar & self_shift, const at::Tensor & other, const at::Scalar & other_zero_point, const at::Scalar & other_multiplier, const at::Scalar & other_shift, const at::Scalar & output_zero_point, const at::Scalar & output_multiplier, const at::Scalar & output_shift);
TORCH_API at::Tensor & quantized_add_out(const at::Tensor & self, const at::Scalar & self_zero_point, const at::Scalar & self_multiplier, const at::Scalar & self_shift, const at::Tensor & other, const at::Scalar & other_zero_point, const at::Scalar & other_multiplier, const at::Scalar & other_shift, const at::Scalar & output_zero_point, const at::Scalar & output_multiplier, const at::Scalar & output_shift, at::Tensor & out);
} // namespace native
} // namespace cortex_m
