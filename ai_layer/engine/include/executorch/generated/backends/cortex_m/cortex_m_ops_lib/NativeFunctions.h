/*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 * All rights reserved.
 *
 * This source code is licensed under the BSD-style license found in the
 * LICENSE file in the root directory of this source tree.
 */

// clang-format off
#pragma once

#include <tuple>

#include <executorch/runtime/core/exec_aten/exec_aten.h> // at::Tensor etc.
#include <executorch/runtime/kernel/kernel_runtime_context.h>
#include <executorch/runtime/core/error.h>

// @generated by gen.py from NativeFunctions.h

namespace cortex_m {
namespace native {
torch::executor::Tensor & quantize_per_tensor_out(const torch::executor::Tensor & input, double scale, int64_t zero_point, int64_t quant_min, int64_t quant_max, torch::executor::ScalarType dtype, torch::executor::Tensor & out);
torch::executor::Tensor & quantize_per_tensor_out(torch::executor::KernelRuntimeContext & context, const torch::executor::Tensor & input, double scale, int64_t zero_point, int64_t quant_min, int64_t quant_max, torch::executor::ScalarType dtype, torch::executor::Tensor & out);
torch::executor::Tensor & dequantize_per_tensor_out(const torch::executor::Tensor & input, double scale, int64_t zero_point, int64_t quant_min, int64_t quant_max, torch::executor::ScalarType dtype, torch::executor::Tensor & out);
torch::executor::Tensor & dequantize_per_tensor_out(torch::executor::KernelRuntimeContext & context, const torch::executor::Tensor & input, double scale, int64_t zero_point, int64_t quant_min, int64_t quant_max, torch::executor::ScalarType dtype, torch::executor::Tensor & out);
torch::executor::Tensor quantized_add(const torch::executor::Tensor & self, const torch::executor::Scalar & self_zero_point, const torch::executor::Scalar & self_multiplier, const torch::executor::Scalar & self_shift, const torch::executor::Tensor & other, const torch::executor::Scalar & other_zero_point, const torch::executor::Scalar & other_multiplier, const torch::executor::Scalar & other_shift, const torch::executor::Scalar & output_zero_point, const torch::executor::Scalar & output_multiplier, const torch::executor::Scalar & output_shift);
torch::executor::Tensor quantized_add(torch::executor::KernelRuntimeContext & context, const torch::executor::Tensor & self, const torch::executor::Scalar & self_zero_point, const torch::executor::Scalar & self_multiplier, const torch::executor::Scalar & self_shift, const torch::executor::Tensor & other, const torch::executor::Scalar & other_zero_point, const torch::executor::Scalar & other_multiplier, const torch::executor::Scalar & other_shift, const torch::executor::Scalar & output_zero_point, const torch::executor::Scalar & output_multiplier, const torch::executor::Scalar & output_shift);
torch::executor::Tensor & quantized_add_out(const torch::executor::Tensor & self, const torch::executor::Scalar & self_zero_point, const torch::executor::Scalar & self_multiplier, const torch::executor::Scalar & self_shift, const torch::executor::Tensor & other, const torch::executor::Scalar & other_zero_point, const torch::executor::Scalar & other_multiplier, const torch::executor::Scalar & other_shift, const torch::executor::Scalar & output_zero_point, const torch::executor::Scalar & output_multiplier, const torch::executor::Scalar & output_shift, torch::executor::Tensor & out);
torch::executor::Tensor & quantized_add_out(torch::executor::KernelRuntimeContext & context, const torch::executor::Tensor & self, const torch::executor::Scalar & self_zero_point, const torch::executor::Scalar & self_multiplier, const torch::executor::Scalar & self_shift, const torch::executor::Tensor & other, const torch::executor::Scalar & other_zero_point, const torch::executor::Scalar & other_multiplier, const torch::executor::Scalar & other_shift, const torch::executor::Scalar & output_zero_point, const torch::executor::Scalar & output_multiplier, const torch::executor::Scalar & output_shift, torch::executor::Tensor & out);
} // namespace native
} // namespace cortex_m
